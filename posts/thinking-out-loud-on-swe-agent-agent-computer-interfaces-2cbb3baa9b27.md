---
title: "Thinking-Out-Loud on “SWE Agent |Agent-Computer Interfaces”"
date: "2024-06-07"
coverImage: "https://cdn-images-1.medium.com/max/1024/1*LDVigKTH9e33Jk4GLqx-jw.png"
canonical: "https://medium.com/@prdeepak.babu/thinking-out-loud-on-swe-agent-agent-computer-interfaces-2cbb3baa9b27"
mediumId: "2cbb3baa9b27"
source: "medium"
---

<section name="ea5d" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="d3b3" id="d3b3" class="graf graf--p graf-after--h3">Welcome to “Thinking-Out-Loud,” a series where I delve into intriguing research papers and share my spontaneous reflections, insights, and personal experiences. Each post will explore a different paper, connecting theoretical findings with practical applications and my own journey in the world of AI and machine learning.</p><p name="daea" id="daea" class="graf graf--p graf-after--p">We are kicking-off this series with an interesting paper on ACI. I recently enjoyed reading a fascinating paper on SWE-Agent from Princeton University. The authors delve into the necessity for an Agent-Computer Interface (ACI) akin to the Human-Computer Interface (HCI), specifically tailored for Large Language Model (LLM) agents. Through their ablation studies, they demonstrate a remarkable 10 percentage point improvement in SWE-Bench test issues over a baseline that employs a standard Linux shell.</p><h3 name="8693" id="8693" class="graf graf--h3 graf-after--p">Understanding the Need for ACI #Thoughts</h3><p name="7c26" id="7c26" class="graf graf--p graf-after--h3">Traditional interfaces built for human consumption are optimized for delivering details and information through visuals and text. While effective for human users, these interfaces can hinder LLMs during long multi-turn dialogues. The context length limits of LLMs can be quickly reached, impacting latency and leading to the “lost-in-the-middle” problem observed in long-context LLMs.</p><p name="8b30" id="8b30" class="graf graf--p graf-after--figure">LLM agents require interfaces that provide concise and relevant feedback to maintain efficiency and effectiveness. For instance, receiving an errored line number in a file may be less efficient than referencing a key from a semantic search database, especially in complex codebases indexed in vector databases.<br>Other reasons why this is important</p><ul class="postList"><li name="7575" id="7575" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Compact Feedback</strong>: Agentic workflows often need confirmations and compact error messages to recover from errors effectively. Detailed feedback designed for human understanding can overload the agent, leading to inefficiencies.</li><li name="646e" id="646e" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Error Recovery</strong>: Efficient error recovery mechanisms, such as semantic search references, can significantly enhance the agent’s ability to navigate complex codebases.</li><li name="ee37" id="ee37" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">State Logging</strong>: Logging states and actions taken during complex workflows is essential for backtracking and error correction. This approach ensures that agents can learn from their mistakes and improve over time.</li></ul><h3 name="ca3f" id="ca3f" class="graf graf--h3 graf-after--li">Reflections and Future Directions</h3><p name="40d6" id="40d6" class="graf graf--p graf-after--h3">Reflecting on my journey, I recall building my first agent use-case back in early 2023. I used OpenAI APIs and native Python to implement the ReACT framework and orchestration. Early iterations of frameworks like LangChain, AutoGen, and Crew started as thin wrappers supporting simple chaining and LLM usage. Over time, these frameworks have evolved to provide tools, orchestration, logging, and more, enabling the construction of complex agent workflows.</p><p name="8485" id="8485" class="graf graf--p graf-after--p">For the past eight months, I have heavily relied on these abstractions, which have greatly benefited me by freeing up time to tackle higher-order problems. The continuous development of these frameworks has been instrumental in automating workflows, and I look forward to seeing the innovations from SWE-Agent integrated into these tools soon.</p><h3 name="8c76" id="8c76" class="graf graf--h3 graf-after--p">References</h3><ol class="postList"><li name="ad98" id="ad98" class="graf graf--li graf-after--h3"><strong class="markup--strong markup--li-strong">SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering</strong><br><a href="https://arxiv.org/abs/2405.15793" data-href="https://arxiv.org/abs/2405.15793" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Link to Paper</a></li><li name="2a02" id="2a02" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">ReAct: Synergizing Reasoning and Acting in Language Models</strong><br><a href="https://arxiv.org/abs/2210.03629" data-href="https://arxiv.org/abs/2210.03629" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Link to Paper</a></li><li name="8859" id="8859" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Lost in the Middle: How Language Models Use Long Contexts</strong><br><a href="https://arxiv.org/pdf/2307.03172" data-href="https://arxiv.org/pdf/2307.03172" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Link to Paper</a></li></ol><div name="cc8f" id="cc8f" class="graf graf--mixtapeEmbed graf-after--li graf--trailing"><a href="https://www.linkedin.com/embed/feed/update/urn:li:share:7204645418385702912" data-href="https://www.linkedin.com/embed/feed/update/urn:li:share:7204645418385702912" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://www.linkedin.com/embed/feed/update/urn:li:share:7204645418385702912"><strong class="markup--strong markup--mixtapeEmbed-strong">Deepak Babu P R on LinkedIn: #multimodality #llm #agents #sweagent #langchain #crewai #multiagent</strong><br><em class="markup--em markup--mixtapeEmbed-em">I enjoyed reading this paper on SWE-Agent[1] from Princeton University, Authors discuss the need for ACI…</em>www.linkedin.com</a><a href="https://www.linkedin.com/embed/feed/update/urn:li:share:7204645418385702912" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="ee7f7bd48d5b53a83695b9e70648e0c1" data-thumbnail-img-id="0*q5E12u6zKrVkIZe9" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*q5E12u6zKrVkIZe9);"></a></div></div></div></section>

<hr>

<p><em>Originally published on Medium:</em> <a href="https://medium.com/@prdeepak.babu/thinking-out-loud-on-swe-agent-agent-computer-interfaces-2cbb3baa9b27">https://medium.com/@prdeepak.babu/thinking-out-loud-on-swe-agent-agent-computer-interfaces-2cbb3baa9b27</a></p>
