---
title: "Abundance, Jobs, and Specialists: The Missing Connection"
date: "2026-01-20"
coverImage: "https://cdn-images-1.medium.com/max/1024/1*5LxBaix-bDtnesfhKS0tDg.png"
canonical: "https://medium.com/@prdeepak.babu/abundance-jobs-and-specialists-the-missing-connection-a82cf5318f01"
mediumId: "a82cf5318f01"
source: "medium"
---

<section name="a93a" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="bdd2" id="bdd2" class="graf graf--h3 graf-after--h3">Introduction</h3><p name="74d4" id="74d4" class="graf graf--p graf-after--h3">I’ve been working in and around AI research and applied machine learning for close to two decades now. I’ve lived through multiple hype cycles, winter cycles, algorithmic plateaus, infrastructure transitions, and the long slow grind of enterprise adoption. I’ve also been using AI systems not just as an observer, but as an operator — an early user of GPT-3 and its descendants, experimenting with agents for coding, research, and ideation before most people even believed those workflows made sense.</p><p name="689c" id="689c" class="graf graf--p graf-after--p">Something changed around late 2025. Working with the latest <a href="https://www.anthropic.com/claude/opus" data-href="https://www.anthropic.com/claude/opus" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Claude Opus</a> models and the new GPT Codex stacks felt noticeably different — not an incremental improvement, but a genuine step-function shift in capability.</p><p name="ac4a" id="ac4a" class="graf graf--p graf-after--figure">Coding that once required human scaffolding — designing architecture, writing glue code, debugging edge conditions — started disappearing from my daily workload. I found myself shipping production-ready pieces end-to-end with an agent handling 80–90% of the operational effort. And even when human involvement was still required at the system level — reviewing safety boundaries, validating integration points, understanding tradeoffs — the nature of that involvement had changed. It was higher-altitude, more purposeful, more about orchestration than construction.</p><p name="42fe" id="42fe" class="graf graf--p graf-after--p">That shift unlocked something unexpected. There’s a new feeling I’ve been trying to name lately. It’s not excitement, not anxiety, and not exactly overwhelm — though it has elements of all three. The closest word I’ve found is <strong class="markup--strong markup--p-strong">abundance</strong>. Once you experience it, many narratives around layoffs, job loss, and “AI replacing people” start to feel outdated, almost like they belong to the wrong decade. Especially if you’re someone who plays near the frontier, you can’t help but notice how different the new world feels compared to the old one.</p><h3 name="b398" id="b398" class="graf graf--h3 graf-after--p">Abundance</h3><p name="39f6" id="39f6" class="graf graf--p graf-after--h3">For me, abundance shows up as the gap between how many ideas I generate and how many hours I have. Before AI, ideas were expensive — a research direction, a product concept, or a technical experiment required scheduling, resources, and a lot of typing. Today, I generate more viable ideas in a single day than I realistically have time to explore in a month. And these aren’t vague “wouldn’t it be cool if…” ideas. They’re things I could prototype tonight.</p><p name="061f" id="061f" class="graf graf--p graf-after--p">It got to a point where typing became the bottleneck. So I switched to voice. I now use voice notes to draft ideas, dictate long prompts, and talk to frontier models when I’m walking between places or sitting in a car. It’s bizarre to admit this, but conversation feels more natural than typing when you have a stream of thoughts you want to explore. The AI understands context, rewrites my ramble into structure, and gives me new angles to explore. That would have sounded like science fiction two years ago.</p><p name="95ae" id="95ae" class="graf graf--p graf-after--p">This inversion — where ideation and execution both become cheap — is the emotional signature of the AI abundance era. Imagination becomes the constraint. And yet, many companies still behave like we’re in a scarcity era, treating AI as a cost-cutting lever rather than a surface-area expansion lever. The irony is that people who actually use these tools daily don’t become lazy. They become overwhelmed by how many new things they could build.</p><h3 name="2985" id="2985" class="graf graf--h3 graf-after--p">The Shrinking Value of Expertise</h3><p name="ec6c" id="ec6c" class="graf graf--p graf-after--h3">Abundance also forces us to re-evaluate what “expertise” means. For centuries, specialization was valuable because knowledge was scarce. Apprenticeship was slow, textbooks were outdated, and domain knowledge belonged to those who had paid their dues. But what happens when knowledge becomes abundant and execution becomes fluid?</p><p name="e8ae" id="e8ae" class="graf graf--p graf-after--p">An<a href="https://tv.apple.com/us/show/pluribus/umc.cmc.37axgovs2yozlyh3c2cmwzlza?utm_source=chatgpt.com" data-href="https://tv.apple.com/us/show/pluribus/umc.cmc.37axgovs2yozlyh3c2cmwzlza?utm_source=chatgpt.com" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"> Apple show </a>called <em class="markup--em markup--p-em">Pluribus (</em>or<em class="markup--em markup--p-em"> Plur1bus) </em>explores this in a wonderfully provocative way. In one scene, a janitor flies a commercial jet. In another, a FedEx delivery guy performs surgery. It’s absurd, but it makes a serious point: if everyone had access to on-demand expertise, what exactly becomes the value of specialization?</p><figure name="299e" id="299e" class="graf graf--figure graf--iframe graf-after--p"><iframe src="https://www.youtube.com/embed/a6lzvWby9UE?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe></figure><p name="fc53" id="fc53" class="graf graf--p graf-after--figure">We are already seeing early versions of this in real life: teenagers fine-tuning models, designers writing backend code, salespeople building analytics pipelines, and founders without CS degrees orchestrating agents. AI doesn’t remove deep specialists — it compresses the <em class="markup--em markup--p-em">operational execution layer</em> that used to separate specialists from non-specialists. When that layer compresses, the premium shifts from knowing <strong class="markup--strong markup--p-strong">how</strong> to execute toward knowing <strong class="markup--strong markup--p-strong">what</strong>, <strong class="markup--strong markup--p-strong">why</strong>, and <strong class="markup--strong markup--p-strong">when</strong> to execute — taste, judgment, and problem framing start to matter more than memorized syntax or credentials.</p><p name="cd1f" id="cd1f" class="graf graf--p graf-after--p">So does that mean everyone becomes a generalist? Probably not. Deep specialists will always matter — they advance the frontier, validate correctness, and push against reality’s edges. But what changes is the relationship between depth and breadth. Specialists are no longer linear execution factories — they become multipliers.</p><p name="4271" id="4271" class="graf graf--p graf-after--p">At the same time, we will see more <strong class="markup--strong markup--p-strong">multi-domain humans</strong> — people who are comfortable blending technical skills with product sense, storytelling, communication, and synthesis. These people push ideas from concept to prototype without waiting for permission or perfect clarity. Breadth stops being a sign of shallowness and becomes a sign of <strong class="markup--strong markup--p-strong">connective intelligence</strong>.</p><h3 name="c9c2" id="c9c2" class="graf graf--h3 graf-after--p">Jobs and AI</h3><p name="8854" id="8854" class="graf graf--p graf-after--h3">To talk about jobs properly, we need better language. <a href="https://www.youtube.com/watch?v=k-xtmISBCNE&amp;list=WL&amp;index=13&amp;t=543s" data-href="https://www.youtube.com/watch?v=k-xtmISBCNE&amp;list=WL&amp;index=13&amp;t=543s" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Jensen Huang provides a useful framing</a>: <strong class="markup--strong markup--p-strong">every job has two components — purpose and tasks</strong>. Tasks are what we do; purpose is why the job exists. When people talk about AI “taking jobs,” they’re almost always talking about tasks. But purpose rarely disappears.</p><p name="d675" id="d675" class="graf graf--p graf-after--p">Take software engineering. Today, tasks are coding, debugging, testing, documenting. But the purpose is solving a customer problem through software. As AI agents handle more of the coding and debugging, engineers don’t vanish — they move closer to purpose: problem decomposition, architecture, validation, user alignment, and systems thinking. The same applies to medicine, law, design, sales, and research. When tasks compress, purpose expands.</p><blockquote name="9896" id="9896" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p"><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">“Every human job has always been a blend of tasks and purpose. AI automates the tasks — the syntax, the glue code, the paperwork, the execution — but it has no intrinsic sense of why anything should exist in the first place. The paradox of the next decade is that as tasks vanish, purpose expands; we don’t lose the job, we lose the tedious scaffolding around the job and are forced to confront the part that was always uniquely ours.”</em></strong></blockquote><p name="9c6c" id="9c6c" class="graf graf--p graf-after--blockquote">And here’s the part most companies miss: when purpose expands, you don’t need fewer people — you often need <strong class="markup--strong markup--p-strong">more</strong>. More surface area, more exploration, more product directions, more experimentation. Companies that get this are the ones who ask, “Now that we’ve automated X, what are the <strong class="markup--strong markup--p-strong">10 new things</strong> we can finally attempt?” They see AI as leverage, not threat.</p><p name="f737" id="f737" class="graf graf--p graf-after--p">Meanwhile, companies responding to AI with layoffs are, bluntly, thinking like the previous generation. They are optimizing the world that is disappearing rather than the world that is emerging. If you were recently laid off, don’t internalize that as a failure. Many layoffs today are signals of companies that don’t understand the era change and are walking downhill when they could be sprinting uphill. The next hypergrowth companies will be the ones who treat AI as a surface-area expansion engine, not a cost-cutting blade.</p><h3 name="d298" id="d298" class="graf graf--h3 graf-after--p">Conclusion</h3><p name="0615" id="0615" class="graf graf--p graf-after--h3">When we connect the dots, a new picture emerges. Abundance captures the emotional inversion of ideation outpacing execution. Expertise shifts not because depth disappears but because execution becomes cheaper, making breadth more valuable. The balance between generalists and specialists rearranges around purpose, not tasks. And Jensen’s framing shows why humans remain central even as tasks get automated.</p><blockquote name="fc4c" id="fc4c" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p"><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">“Companies that see AI as a cost-cutting tool will shrink into irrelevance, because they are optimizing for a world that is already ending. The companies that treat AI as a surface-area expansion engine — one that allows their people to explore ten new opportunities for every task automated — will discover that headcount was never the constraint; imagination was. Layoffs are often just a symptom of leadership that cannot see new markets.”</em></strong></blockquote><p name="26b0" id="26b0" class="graf graf--p graf-after--blockquote">One last thing I want to emphasize: <strong class="markup--strong markup--p-strong">AI capabilities are not static</strong>. Don’t judge today’s AI based on your first impression from early 2023 or whatever moment you tried ChatGPT once and moved on. The models I talk to today are not the models from even six months ago. Keep trying, keep refining your mental model of what AI is currently capable of. Gen Z does this naturally — they are AI-native in their thinking, unburdened by old assumptions. Senior folks like us often have decades of patterns that work against us unless we consciously adapt.</p><p name="abbe" id="abbe" class="graf graf--p graf-after--p">The scarce things in the future will not be technical skills or credentials — those will be abundant. The scarce things will be purpose, taste, ethics, curiosity, and imagination. AI makes knowledge abundant and execution cheap. Humans supply meaning and direction. The future isn’t machines replacing people or people resisting machines — it’s people using machines to go further into the parts of work that are actually human.</p><blockquote name="39fd" id="39fd" class="graf graf--blockquote graf-after--p graf--trailing">If this topic resonated, highlight or leave a note — I’m collecting diverse perspectives for a follow-up piece.</blockquote></div></div></section>

<hr>

<p><em>Originally published on Medium:</em> <a href="https://medium.com/@prdeepak.babu/abundance-jobs-and-specialists-the-missing-connection-a82cf5318f01">https://medium.com/@prdeepak.babu/abundance-jobs-and-specialists-the-missing-connection-a82cf5318f01</a></p>
