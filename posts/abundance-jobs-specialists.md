# Abundance, Jobs, and Specialists: The Missing Connection

*Jan 19, 2026*

## Introduction
I've been working in and around AI research and applied machine learning for close to two decades now. I've lived through multiple hype cycles, winter cycles, algorithmic plateaus, infrastructure transitions, and the long slow grind of enterprise adoption. I've also been using AI systems not just as an observer, but as an operator - an early user of GPT-3 and its descendants, experimenting with agents for coding, research, and ideation before most people even believed those workflows made sense.

Something changed around late 2025. Working with the latest Claude Opus models and the new GPT Codex stacks felt noticeably different - not an incremental improvement, but a genuine step-function shift in capability.

![Comic on abundance and specialists](blog-images/abundance.png)

Coding that once required human scaffolding - designing architecture, writing glue code, debugging edge conditions - started disappearing from my daily workload. I found myself shipping production-ready pieces end-to-end with an agent handling 80-90% of the operational effort. And even when human involvement was still required at the system level - reviewing safety boundaries, validating integration points, understanding tradeoffs - the nature of that involvement had changed. It was higher-altitude, more purposeful, more about orchestration than construction.

That shift unlocked something unexpected. There is a new feeling I've been trying to name lately. It's not excitement, not anxiety, and not exactly overwhelm - though it has elements of all three. The closest word I've found is **abundance**. Once you experience it, many narratives around layoffs, job loss, and "AI replacing people" start to feel outdated, almost like they belong to the wrong decade. Especially if you are someone who plays near the frontier, you cannot help but notice how different the new world feels compared to the old one.

## Abundance
For me, abundance shows up as the gap between how many ideas I generate and how many hours I have. Before AI, ideas were expensive - a research direction, a product concept, or a technical experiment required scheduling, resources, and a lot of typing. Today, I generate more viable ideas in a single day than I realistically have time to explore in a month. And these are not vague "wouldn't it be cool if..." ideas. They are things I could prototype tonight.

It got to a point where typing became the bottleneck. So I switched to voice. I now use voice notes to draft ideas, dictate long prompts, and talk to frontier models when I am walking between places or sitting in a car. It's bizarre to admit this, but conversation feels more natural than typing when you have a stream of thoughts you want to explore. The AI understands context, rewrites my ramble into structure, and gives me new angles to explore. That would have sounded like science fiction two years ago.

This inversion - where ideation and execution both become cheap - is the emotional signature of the AI abundance era. Imagination becomes the constraint. And yet, many companies still behave like we are in a scarcity era, treating AI as a cost-cutting lever rather than a surface-area expansion lever. The irony is that people who actually use these tools daily do not become lazy. They become overwhelmed by how many new things they could build.

## The Shrinking Value of Expertise
Abundance also forces us to re-evaluate what "expertise" means. For centuries, specialization was valuable because knowledge was scarce. Apprenticeship was slow, textbooks were outdated, and domain knowledge belonged to those who had paid their dues. But what happens when knowledge becomes abundant and execution becomes fluid?

An Apple show called *Pluribus* (or *Plur1bus*) explores this in a wonderfully provocative way. In one scene, a janitor flies a commercial jet. In another, a FedEx delivery guy performs surgery in a bathroom. It's absurd, but it makes a serious point: if everyone had access to on-demand expertise, what exactly becomes the value of specialization?

We are already seeing early versions of this in real life: teenagers fine-tuning models, designers writing backend code, salespeople building analytics pipelines, and founders without CS degrees orchestrating agents. AI does not remove deep specialists - it compresses the operational execution layer that used to separate specialists from non-specialists. When that layer compresses, the premium shifts from knowing how to execute toward knowing what, why, and when to execute. **Taste, judgment, and problem framing** start to matter more than memorized syntax or credentials.

So does that mean everyone becomes a generalist? Probably not. Deep specialists will always matter - they advance the frontier, validate correctness, and push against reality's edges. But what changes is the relationship between depth and breadth. Specialists are no longer linear execution factories - they become multipliers.

At the same time, we will see more multi-domain humans - people who are comfortable blending technical skills with product sense, storytelling, communication, and synthesis. These people push ideas from concept to prototype without waiting for permission or perfect clarity. Breadth stops being a sign of shallowness and becomes a sign of connective intelligence.

## Jobs and AI
To talk about jobs properly, we need better language. Jensen Huang provides a useful framing: every job has two components - purpose and tasks. Tasks are what we do; purpose is why the job exists. When people talk about AI "taking jobs," they are almost always talking about tasks. But purpose rarely disappears.

Take software engineering. Today, tasks are coding, debugging, testing, documenting. But the purpose is solving a customer problem through software. As AI agents handle more of the coding and debugging, engineers do not vanish - they move closer to purpose: problem decomposition, architecture, validation, user alignment, and systems thinking. The same applies to medicine, law, design, sales, and research. When tasks compress, purpose expands.

And here is the part most companies miss: when purpose expands, you do not need fewer people - you often need more. More surface area, more exploration, more product directions, more experimentation. Companies that get this are the ones who ask, "Now that we have automated X, what are the 10 new things we can finally attempt?" They see AI as leverage, not threat.

Meanwhile, companies responding to AI with layoffs are, bluntly, thinking like the previous generation. They are optimizing the world that is disappearing rather than the world that is emerging. If you were recently laid off, do not internalize that as a failure. Many layoffs today are signals of companies that do not understand the era change and are walking downhill when they could be sprinting uphill. The next hypergrowth companies will be the ones who treat AI as a surface-area expansion engine, not a cost-cutting blade.

## Conclusion
When we connect the dots, a new picture emerges. Abundance captures the emotional inversion of ideation outpacing execution. Expertise shifts not because depth disappears but because execution becomes cheaper, making breadth more valuable. The balance between generalists and specialists rearranges around purpose, not tasks. And Jensen's framing shows why humans remain central even as tasks get automated.

One last thing I want to emphasize: AI capabilities are not static. Do not judge today's AI based on your first impression from early 2023 or whatever moment you tried ChatGPT once and moved on. The models I talk to today are not the models from even six months ago. Keep trying, keep refining your mental model of what AI is currently capable of. Gen Z does this naturally - they are AI-native in their thinking, unburdened by old assumptions. Senior folks like us often have decades of patterns that work against us unless we consciously adapt.

The scarce things in the future will not be technical skills or credentials - those will be abundant. The scarce things will be purpose, taste, ethics, curiosity, and imagination. AI makes knowledge abundant and execution cheap. Humans supply meaning and direction. The future is not machines replacing people or people resisting machines - it is people using machines to go further into the parts of work that are actually human.

If this topic resonated, highlight or leave a note - I am collecting diverse perspectives for a follow-up piece.
