---
title: "Journey from traditional IR to RAG to agentic-RAG"
date: "2025-01-06"
coverImage: "https://cdn-images-1.medium.com/max/1024/1*BS_4qqWfmv9jRnYrK84cXQ.png"
canonical: "https://medium.com/@prdeepak.babu/journey-from-traditional-ir-to-rag-to-agentic-rag-b658210f46d4"
mediumId: "b658210f46d4"
source: "medium"
---

<section name="f421" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="dab5" id="dab5" class="graf graf--p graf-after--h3">Information systems have evolved from simple keyword-based search engines to sophisticated natural language-based question-answering (QA) systems. I distinctly remember my early days in 2012, building search engines for an e-commerce company and fine-tuning relevance functions on Solr. Back then, documents were indexed using traditional count-based techniques like <strong class="markup--strong markup--p-strong">TF-IDF</strong> and <strong class="markup--strong markup--p-strong">BM25</strong>, collectively known as <strong class="markup--strong markup--p-strong">term-based retrieval</strong>. These systems were highly dependent on exact keyword matches, query expansion, and manually tuned relevance metrics.</p><p name="708f" id="708f" class="graf graf--p graf-after--p">Fast forward to 2024, the landscape has shifted dramatically. Modern information systems have moved far beyond term-based retrieval to <strong class="markup--strong markup--p-strong">semantic retrieval</strong>, leveraging dense representations from models like <strong class="markup--strong markup--p-strong">BERT</strong> to index and retrieve documents. The emergence of <strong class="markup--strong markup--p-strong">retrieval-augmented generation (RAG)</strong> has further transformed how we interact with and retrieve information by seamlessly combining <strong class="markup--strong markup--p-strong">retrieval</strong> and <strong class="markup--strong markup--p-strong">generation</strong> in intelligent systems. Building on RAG, the rise of <strong class="markup--strong markup--p-strong">Agentic RAG</strong> in 2024 introduces systems capable of reasoning, adapting, and answering complex queries autonomously.</p><p name="5c88" id="5c88" class="graf graf--p graf-after--figure">In this blog post, I aim to summarize the trends I’ve observed from working on early information retrieval (IR) systems to the present day. Broadly, the evolution of IR can be categorized into <strong class="markup--strong markup--p-strong">five distinct phases</strong>: Sparse Retrieval, Dense Retrieval, Semantic Search, RAG, and Agentic RAG.</p><ul class="postList"><li name="bec7" id="bec7" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Sparse Retrieval (Pre-2012) The Era of Keyword Search</strong><br>Sparse retrieval relied on bag-of-words representations, where documents were represented as vectors indicating word occurrences. These representations were sparse because their dimensionality matched the size of the vocabulary, with most dimensions being zero for any given document. Sparse retrieval used term-based relevance metrics like TF-IDF and BM25, which scored documents based on the frequency of keywords in the query and the document corpus. The system ignored word order, context, or semantics, focusing purely on word occurrence. Enhancements such as query expansion for synonyms or similar terms, spell correction, query boosting, and query chains were common, refining search to fetch results in the form of links or entities. Sparse retrieval was widely used in e-commerce, web search engines, and early enterprise systems to fetch links or entities based on keyword matches.</li><li name="b687" id="b687" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Dense Retrieval (2013) :Representations Beyond Sparse Features</strong><br>The introduction of dense word embeddings through models like Google’s word2vec marked a major shift in retrieval systems. Word2vec trained neural networks to predict a word’s context from its surroundings, producing low-dimensional, dense word representations. Unlike sparse representations, dense vectors captured semantic similarity, enabling queries like “king” to retrieve results containing “queen” or “royalty” due to proximity in vector space. These embeddings were static, meaning the same word always had the same vector regardless of context (e.g., “bank” in “river bank” and “financial bank”). Despite this limitation, dense retrieval revolutionized tasks like semantic similarity and document ranking, enabling more relevant results than sparse retrieval could achieve.</li><li name="58f7" id="58f7" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Semantic Search (2018): The Rise of BERT and Contextual Understanding</strong><br>Google’s BERT introduced transformer-based architectures and the attention mechanism to learn contextual embeddings for words, subwords, and sentences, marking the beginning of semantic search. BERT’s embeddings changed based on context, capturing nuanced meanings of words in different phrases. It also introduced subword tokenization to handle rare or unknown words effectively. By training on tasks like masked language modeling and next sentence prediction, BERT improved understanding of text structure and semantics. To enable fast and scalable retrieval, semantic search systems employed Approximate Nearest Neighbors (ANN) techniques to retrieve documents using these dense representations. This phase of IR revolutionized FAQ systems, chatbots, and search engines where context-sensitive understanding was crucial.</li><li name="9d52" id="9d52" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">RAG(2022) :Beyond Retrieval to Reasoning and Summarization</strong><br>The advent of GPT-3.5 and products like ChatGPT marked the emergence of retrieval-augmented generation (RAG). This approach combined retrieval with powerful generative models to synthesize coherent and compact responses. Instead of merely retrieving links, RAG systems generated summaries and reasoned over the retrieved information. Early RAG systems focused on multi-source summarization, retrieving content from multiple sources and combining them into a single, cohesive response. However, the reasoning capabilities were limited in the early versions, as they struggled with complex, multi-step reasoning tasks or handling ambiguous queries. RAG transformed QA systems by providing concise, human-like responses instead of presenting a list of links.</li><li name="ea0c" id="ea0c" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Agentic RAG (2024): Intelligent Reasoning and Adaptation</strong><br>The integration of frontier models like GPT-4 and beyond enabled the development of Agentic RAG systems. These systems go a step further by incorporating reasoning, adaptation, and iterative problem-solving. Agentic RAG dynamically refines its queries, adapting to new information as it processes user input. It autonomously handles multi-step queries, resolves ambiguities, and synthesizes responses involving logical reasoning. These systems are goal-oriented, breaking down complex questions into smaller sub-tasks, retrieving relevant information, and generating comprehensive answers iteratively. Applications of Agentic RAG include technical support, scientific research assistants, medical diagnosis systems, and advanced chatbots. For instance, answering a question like “What are Tesla’s yearly sales since 2010?” involves retrieving, cross-checking, and synthesizing data from multiple sources dynamically, showcasing the adaptive reasoning capabilities of Agentic RAG systems.</li></ul><h3 name="5572" id="5572" class="graf graf--h3 graf-after--li">Era of Agentic RAG</h3><p name="2ad9" id="2ad9" class="graf graf--p graf-after--h3">So, what makes RAG different from Agentic RAG? Agentic RAG adopts a <strong class="markup--strong markup--p-strong">goal-oriented approach</strong> to answering complex questions that require multiple reasoning steps or hops. If we go back 10 years in time, such questions were not expected to be answered by even the best search engines, like Google. Instead, humans would decompose the problem, conduct multiple searches, and manually piece together the information to find the solution. With frontier models like GPT-4, Gemini, and LLaMA, we are observing a shift where users now expect search engines and bots to handle this complexity. These systems are increasingly expected to decompose queries, perform iterative reasoning, and generate cohesive answers in the way humans traditionally approached such problems.</p><p name="459f" id="459f" class="graf graf--p graf-after--p">Answering complex questions in real time makes this an exciting engineering challenge that blends reasoning with performance optimization. At its core, an Agentic RAG system consists of three key components:</p><ol class="postList"><li name="e26f" id="e26f" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">LLM (Large Language Model)</strong>: Acts as the brain of the system, handling reasoning and natural language understanding.</li><li name="15f9" id="15f9" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Knowledge Bases (KBs)</strong>: Serve as memory, providing access to external information sources.</li><li name="ad10" id="ad10" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Code Interpreters and APIs</strong>: Function as tools for computations, query refinement, and data retrieval.</li></ol><p name="e7cc" id="e7cc" class="graf graf--p graf-after--li">These components operate within a <a href="https://arxiv.org/abs/2309.02427" data-href="https://arxiv.org/abs/2309.02427" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">cognitive architecture</strong></a> that orchestrates their interplay seamlessly. Let’s illustrate this with an example problem to demonstrate the working of an Agentic RAG system.</p><figure name="18a3" id="18a3" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*71K1uqtWWsrW9lN_gI3o5g.png" data-width="1920" data-height="1080" src="https://cdn-images-1.medium.com/max/800/1*71K1uqtWWsrW9lN_gI3o5g.png"><figcaption class="imageCaption">How IR systems have evolved in terms of keyword-based searches to NL question-based search aka conversational search</figcaption></figure><p name="959c" id="959c" class="graf graf--p graf-after--figure">The evolution of <strong class="markup--strong markup--p-strong">information retrieval (IR)</strong> systems mirrors the way humans’ search patterns have transformed over time. Fig. 2 highlights this shift, from simple keyword-based searches to <strong class="markup--strong markup--p-strong">natural language (NL) question-based searches</strong>, commonly referred to as <strong class="markup--strong markup--p-strong">conversational search</strong>.</p><p name="5e28" id="5e28" class="graf graf--p graf-after--p">Consider a question like:<br><strong class="markup--strong markup--p-strong">“How many cars did Tesla sell year-by-year from 2014 till date?”</strong>To answer this, an Agentic RAG system would decompose the problem into smaller sub-tasks:</p><ol class="postList"><li name="0c1e" id="0c1e" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Problem Decomposition</strong><br>first, we need to get statistics on car sales by year for the company = tesla. where should we search ? may be search annual reports ?</li><li name="e2be" id="e2be" class="graf graf--li graf-after--li">search “tesla car sales 2014”, “tesla car sales 2015” and so on until “tesla car sales 2024” <br>- there are couple additional choices we need to make here that decides the overall latency of the system (a) should we trigger these searches in parallel ? (b) should we trigger these searches sequentially ? <br>clearly (a) would be more efficient than (b) for runtime standpoint and probably doesnt harm accuracy of the result as it has little effect on the final result.</li><li name="1767" id="1767" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Retrieval </strong>lets assume parallel/serials calls from (2) resulted in a dictionary object in python of the form below (with year as key and sales as value)</li></ol><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="json" name="4d92" id="4d92" class="graf graf--pre graf-after--li graf--preV2"><span class="pre--content">yearly_sales = <span class="hljs-punctuation">{</span>&#x27;<span class="hljs-number">2014</span>&#x27;<span class="hljs-punctuation">:</span>&#x27;<span class="hljs-number">31655</span>&#x27;<span class="hljs-punctuation">,</span> <br />                &#x27;<span class="hljs-number">2015</span>&#x27;<span class="hljs-punctuation">:</span> &#x27;<span class="hljs-number">50580</span>&#x27;<span class="hljs-punctuation">,</span> <br />                &#x27;<span class="hljs-number">2016</span>&#x27;<span class="hljs-punctuation">:</span>&#x27;<span class="hljs-number">76230</span>&#x27;<span class="hljs-punctuation">,</span> .... <br />                .<br />                &#x27;<span class="hljs-number">2024</span>&#x27;<span class="hljs-punctuation">:</span>&#x27;<span class="hljs-number">1789226</span>&#x27;<span class="hljs-punctuation">}</span></span></pre><p name="3cb0" id="3cb0" class="graf graf--p graf-after--pre">4. <strong class="markup--strong markup--p-strong">Language Understanding</strong><br>User is likely interested in sales till date from 2014. so we should do a <em class="markup--em markup--p-em">sum(yearly_sales.values())<br></em>How do we do ? we will let LLM choose python code interpreter as a tool to write the code to get yearly</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="25ef" id="25ef" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-comment"># Sales data</span><br />sales = [<span class="hljs-number">31655</span>, <span class="hljs-number">50580</span>, <span class="hljs-number">76230</span>, <span class="hljs-number">103020</span>, <span class="hljs-number">245240</span>, <span class="hljs-number">367820</span>, <span class="hljs-number">499550</span>, <span class="hljs-number">936172</span>, <span class="hljs-number">1313851</span>, <span class="hljs-number">1800000</span>, <span class="hljs-number">1789226</span>]<br /><br /><span class="hljs-comment"># Calculate the sum of sales</span><br />total_sales = <span class="hljs-built_in">sum</span>(sales)<br />total_sales<br /><br />Result<br /><span class="hljs-number">7213344</span></span></pre><p name="6eee" id="6eee" class="graf graf--p graf-after--pre">5. <strong class="markup--strong markup--p-strong">Answer Generation</strong> <br>Finally, generate an answer in the best possible way to answer the question (if all the data needed to answer is gathered and ready?)<br>This is again not a simple question since the user has asked sales till date and also year-by-year so you could display the total 7,213,344 and also display the yearly data in the form of a table ? a chart ?</p><p name="d3eb" id="d3eb" class="graf graf--p graf-after--p">As seen in this example, an Agentic RAG system performs several critical tasks:</p><ol class="postList"><li name="6664" id="6664" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Problem Decomposition</strong>: Break down complex queries into manageable sub-problems.</li><li name="5df3" id="5df3" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Data Retrieval</strong>: Retrieve relevant information using efficient strategies (e.g., parallel calls).</li><li name="db55" id="db55" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Code Generation and Execution</strong>: Use tools like code interpreters to handle computations.</li><li name="a380" id="a380" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Language Understanding</strong>: Interpret the user’s intent accurately.</li><li name="a4ee" id="a4ee" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Summarization and UX Generation</strong>: Present the final answer in a user-friendly format, whether as text, tables, or charts.</li></ol><p name="0f42" id="0f42" class="graf graf--p graf-after--li">A <strong class="markup--strong markup--p-strong">cognitive architecture</strong> enables the system to orchestrate these complex workflows with minimal human intervention, allowing it to tackle intricate queries in a way that traditional systems cannot. This capability positions Agentic RAG as the next frontier in conversational search and intelligent information retrieval.</p><div name="2ca5" id="2ca5" class="graf graf--mixtapeEmbed graf-after--p graf--trailing"><a href="https://medium.com/@prdeepak.babu/vertical-ai-and-cognitive-architectures-lessons-from-cloud-and-mobile-transitions-8e87f364721e" data-href="https://medium.com/@prdeepak.babu/vertical-ai-and-cognitive-architectures-lessons-from-cloud-and-mobile-transitions-8e87f364721e" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@prdeepak.babu/vertical-ai-and-cognitive-architectures-lessons-from-cloud-and-mobile-transitions-8e87f364721e"><strong class="markup--strong markup--mixtapeEmbed-strong">Vertical AI and Cognitive Architectures: Lessons from Cloud and Mobile Transitions</strong><br><em class="markup--em markup--mixtapeEmbed-em">As an AI scientist who has been immersed in the field for many years, I’ve witnessed firsthand the grassroots…</em>medium.com</a><a href="https://medium.com/@prdeepak.babu/vertical-ai-and-cognitive-architectures-lessons-from-cloud-and-mobile-transitions-8e87f364721e" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="c4286d8bf3b70e91c8e423aca9f58c65" data-thumbnail-img-id="1*uWIUanyjrR_uqrKug00Cvw.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*uWIUanyjrR_uqrKug00Cvw.png);"></a></div></div></div></section>

<hr>

<p><em>Originally published on Medium:</em> <a href="https://medium.com/@prdeepak.babu/journey-from-traditional-ir-to-rag-to-agentic-rag-b658210f46d4">https://medium.com/@prdeepak.babu/journey-from-traditional-ir-to-rag-to-agentic-rag-b658210f46d4</a></p>
