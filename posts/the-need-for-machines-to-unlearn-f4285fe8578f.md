---
title: "The Need for Machines to Unlearn"
date: "2024-08-27"
coverImage: "https://cdn-images-1.medium.com/max/1024/1*AXM7NNAKaQ5sVK1D1tj3aQ.png"
canonical: "https://medium.com/@prdeepak.babu/the-need-for-machines-to-unlearn-f4285fe8578f"
mediumId: "f4285fe8578f"
source: "medium"
---

<section name="4e66" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="a7af" id="a7af" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--figure"><span class="graf-dropCap">M</span>achine learning (ML) and artificial intelligence (AI) are fundamentally about learning patterns and models from data or a collection of experiences. These experiences can be thought of as individual instances of interaction or data samples. But as these technologies advance and become more integrated into our daily lives, a critical question emerges: why do we need models that can forget specific experiences? Is there a genuine need for AI systems that can unlearn parts of their data? The answer is yes, and there are several compelling reasons for this.</p><p name="5fa7" id="5fa7" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">1. Privacy Laws and the Right to Be Forgotten[1]</strong></p><blockquote name="a762" id="a762" class="graf graf--blockquote graf-after--p">The “Right to be Forgotten” under the GDPR has led to fines when companies fail to comply with user requests to delete personal data.</blockquote><p name="0294" id="0294" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--blockquote"><span class="graf-dropCap">O</span>ne of the primary drivers behind the need for machine unlearning is the evolving landscape of privacy laws. Regulations like the General Data Protection Regulation (GDPR) in the European Union have introduced the concept of the “right to be forgotten.” This right allows individuals to request that their personal data be deleted from an organization’s records, including any AI models trained on that data. For AI systems, this means that models must not only be capable of learning from data but also of forgetting specific pieces of information upon request. For example, if a user requests the deletion of their data, an AI model trained on that data must be able to unlearn the associated patterns and influences derived from it. This capability is crucial for compliance with privacy laws and maintaining user trust.</p><p name="d468" id="d468" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">2. Mitigating Misinformation and Hallucinations</strong></p><p name="6c2d" id="6c2d" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--p"><span class="graf-dropCap">A</span>nother motivation for machine unlearning is the need to address misinformation or “hallucinations” within AI models. Hallucinations in AI refer to instances where a model generates outputs that are not grounded in reality, such as fake news or incorrect information. This can occur because the model has learned from inaccurate or biased data sources. In the context of media and information dissemination, hallucinations can be particularly harmful, spreading false information quickly and widely. By enabling models to unlearn or remove the influence of misleading or incorrect data, we can help ensure that AI systems provide more reliable and accurate information.</p><p name="27b8" id="27b8" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Machine Unlearning[2]: A New Frontier</strong></p><p name="e9be" id="e9be" class="graf graf--p graf-after--p">Machine unlearning is an emerging field focused on developing techniques that can selectively remove the effects of specific learned data from a model. This goes beyond merely deleting data from a dataset; it involves reversing the learning process to erase the impact that particular data had on the model’s parameters.</p><p name="0e7d" id="0e7d" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Connections to Mechanistic Interpretability</strong></p><p name="152f" id="152f" class="graf graf--p graf-after--p">The concept of machine unlearning is closely related to mechanistic interpretability — the study of understanding the internal workings of neural networks. By identifying the specific neurons or pathways in a network that store certain information, we can target those areas for unlearning. This allows us to precisely remove the knowledge or misinformation without affecting the rest of the model’s capabilities.</p><p name="d378" id="d378" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Machine Unlearning vs. Model Editing</strong></p><p name="e350" id="e350" class="graf graf--p graf-after--p">It’s important to distinguish machine unlearning from model editing, a related but distinct process.</p><blockquote name="8d2e" id="8d2e" class="graf graf--blockquote graf--hasDropCapModel graf-after--p">While machine unlearning focuses on erasing information from a model, model editing involves modifying the model’s parameters to correct errors or biases without completely removing the learned information.</blockquote><p name="6509" id="6509" class="graf graf--p graf-after--blockquote">For example, if a model learns an incorrect association, model editing would adjust the relevant parameters to fix the mistake rather than erasing all related data.</p><p name="c30a" id="c30a" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Conclusion</strong></p><p name="dd3d" id="dd3d" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--p"><span class="graf-dropCap">T</span>he need for machines to unlearn is a reflection of our evolving understanding of AI’s role in society. As we continue to integrate these technologies into more aspects of our lives, ensuring that they can learn and unlearn responsibly will be crucial. By developing techniques that allow for targeted unlearning and improving our understanding of model internals through mechanistic interpretability, we can create AI systems that are not only smarter but also safer, fairer, and more aligned with human values.<br> If you’re looking for a challenge in AI research, this is a problem worth solving. With the increasing focus on data privacy and the complexities of digital information landscapes, any advancements in machine unlearning are likely to attract significant attention from major tech companies and regulatory bodies alike.</p><p name="1a51" id="1a51" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">The Path Forward: Research and Development</strong></p><p name="8f07" id="8f07" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--p"><span class="graf-dropCap">If</span> there is one area of AI research that holds significant potential for impact, it is machine unlearning. Developing effective unlearning techniques could revolutionize how we handle data privacy, misinformation, and the dynamic evolution of AI systems. It’s a field that not only has profound ethical implications but is also of immense interest to major tech companies (including FAANG/MANG), given the growing regulatory and social pressures surrounding data use.</p><p name="e26e" id="e26e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">References</strong></p><p name="02be" id="02be" class="graf graf--p graf-after--p">[1] <a href="https://www.cpomagazine.com/data-protection/spain-hands-google-e10-million-gdpr-fine-for-violation-of-right-to-be-forgotten-rules/" data-href="https://www.cpomagazine.com/data-protection/spain-hands-google-e10-million-gdpr-fine-for-violation-of-right-to-be-forgotten-rules/" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://www.cpomagazine.com/data-protection/spain-hands-google-e10-million-gdpr-fine-for-violation-of-right-to-be-forgotten-rules/</a><br>[2] <a href="https://arxiv.org/pdf/2406.06186v1" data-href="https://arxiv.org/pdf/2406.06186v1" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">A Survey on Machine Unlearning: Techniques and New Emerged Privacy Risks</a><br>[3] <a href="https://arxiv.org/abs/2311.05232" data-href="https://arxiv.org/abs/2311.05232" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions</a></p><p name="32a4" id="32a4" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Related Articles</strong></p><div name="33b1" id="33b1" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.com/@prdeepak.babu/decoding-ais-thought-process-mechanistic-interpretability-54db5727e7e8" data-href="https://medium.com/@prdeepak.babu/decoding-ais-thought-process-mechanistic-interpretability-54db5727e7e8" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@prdeepak.babu/decoding-ais-thought-process-mechanistic-interpretability-54db5727e7e8"><strong class="markup--strong markup--mixtapeEmbed-strong">Decoding AI’s Thought Process: Mechanistic Interpretability</strong><br><em class="markup--em markup--mixtapeEmbed-em">Mechanistic Interpretability is a field of study that concerns study of neural networks (more generally ML models) with…</em>medium.com</a><a href="https://medium.com/@prdeepak.babu/decoding-ais-thought-process-mechanistic-interpretability-54db5727e7e8" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="8e21c192664b64e2d42feb22069de72d" data-thumbnail-img-id="0*-Z4XL91lYNGItrL0" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*-Z4XL91lYNGItrL0);"></a></div><div name="ac24" id="ac24" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed graf--trailing"><a href="https://medium.com/@prdeepak.babu/scalable-oversight-in-ai-beyond-human-supervision-d258b50dbf62" data-href="https://medium.com/@prdeepak.babu/scalable-oversight-in-ai-beyond-human-supervision-d258b50dbf62" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@prdeepak.babu/scalable-oversight-in-ai-beyond-human-supervision-d258b50dbf62"><strong class="markup--strong markup--mixtapeEmbed-strong">Scalable Oversight in AI: Beyond Human Supervision</strong><br><em class="markup--em markup--mixtapeEmbed-em">In recent years, the field of artificial intelligence has experienced unprecedented growth. Two driving forces underpin…</em>medium.com</a><a href="https://medium.com/@prdeepak.babu/scalable-oversight-in-ai-beyond-human-supervision-d258b50dbf62" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="f5167fbe68c7f92ff9710560fea490d5" data-thumbnail-img-id="1*S44j_t24sZsIgcMJMh4xLg.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*S44j_t24sZsIgcMJMh4xLg.png);"></a></div></div></div></section>

<hr>

<p><em>Originally published on Medium:</em> <a href="https://medium.com/@prdeepak.babu/the-need-for-machines-to-unlearn-f4285fe8578f">https://medium.com/@prdeepak.babu/the-need-for-machines-to-unlearn-f4285fe8578f</a></p>
