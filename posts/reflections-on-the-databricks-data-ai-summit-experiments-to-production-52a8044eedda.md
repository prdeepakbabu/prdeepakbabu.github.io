---
title: "Reflections on the Databricks Data + AI Summit â€” Experiments to Production"
date: "2024-06-25"
coverImage: "https://cdn-images-1.medium.com/max/1024/1*VEzOYn2yN0ES3d7DOUFTqg.jpeg"
canonical: "https://medium.com/@prdeepak.babu/reflections-on-the-databricks-data-ai-summit-experiments-to-production-52a8044eedda"
mediumId: "52a8044eedda"
source: "medium"
---

<section name="313b" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="f959" id="f959" class="graf graf--p graf-after--h3">I had a fantastic time at the <a href="https://www.databricks.com/dataaisummit" data-href="https://www.databricks.com/dataaisummit" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Databricks Data + AI Summit</a> (DAIS) 2024, connecting with over 2K+ participants from diverse backgrounds, including CXOs and ICs (engineers, scientists, and product managers), all working on applying AI in their respective industries and roles. The keynote, delivered by <a href="https://www.linkedin.com/in/alighodsi/" data-href="https://www.linkedin.com/in/alighodsi/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Ali Ghodsi</a>Â , highlighted a <a href="https://youtu.be/-6dt7eJ3cMs?si=QVjQmFdQ1lGIUmxk&amp;t=1" data-href="https://youtu.be/-6dt7eJ3cMs?si=QVjQmFdQ1lGIUmxk&amp;t=1" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">striking statistic</a> from customer survey: 85% of generative AI (genAI) use cases in enterprises are still experimental and have yet to make it to production.</p><p name="f2cd" id="f2cd" class="graf graf--p graf-after--figure">I wanted to share some insights from my own experience of having worked in big tech for a while, so there could be similar stories in enterprises.</p><p name="63ae" id="63ae" class="graf graf--p graf-after--p">To simplify the discussion, letâ€™s categorize ML/AI developments into two eras: pre-GPT (before 2023) and GPT (since 2023). or may be we should call T5 eraÂ ? Itâ€™s important to note that generative models, such as GANs, RNNs and LSTMs, have existed well before 2023 but were much limited in scale and capability.</p><ol class="postList"><li name="2b7c" id="2b7c" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Switching Costs</strong>: Transitioning from the pre-GPT era to the GPT era incurs significant switching costs, slowing progress and decision-making. GPT era software architectures are substantially different from those in the pre-GPT era. Previously, models were fragmented with task-specific models and datasets orchestrated together. In contrast, GPT-era models are more unified and pre-trained with smaller task-specific datasets. Imagine 2K+ eng &amp; scientists working on pre-GPT models spread across multiple VP-level teams being restructured to GPT-era architecture all of a sudden. It doesnâ€™t work unless there is a top-down mandate from the leadership and aligned AI vision and strategy among the LT teams.</li><li name="b33e" id="b33e" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Rapid Innovation</strong>: The pace of innovation is incredibly fast, posing challenges in keeping up. Should we adopt in-context learning or fine-tune models? Context windows are becoming practically limitlessâ€Šâ€”â€Šdo we still need RAGÂ ? How do we optimize costs and consider agentic AI? What about latencyÂ ? Serving customers at scale requires a fine balance of accuracy, speed and cost. It is easy to pick one and optimize, but gets harder as you start to optimize between competing objectives. The SoTA is fast changing making it hard to keep-up with implementation.</li><li name="6a54" id="6a54" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Hallucinations and Privacy</strong>: Hallucinations (make-up non-existent claims) in AI models are a major threat to businesses built on high trust. This requires knowledge grounding using knowledge graphs or WWW search engines. Another major concern being privacy risks of sending customer data to proprietary model APIs like OpenAI and Anthropic. Should we build a foundation modelÂ ? or adapt open models like Llama to continue pretraining and fine-tune on company datasets.</li><li name="058e" id="058e" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Software 2.0 and Evaluation</strong>: There is a need for a paradigm shift or mindset to adapt to the probabilistic nature of ML systems. Evaluation of systems in the GPT-era has gotten harder. Comparing responses across runs has become less deterministic due to the free-flowing nature of natural language output. Many systems have gotten so good (superhuman) that human annotation based evaluation starts to break, forcing an approach that requires model-based judging and need for scalable oversight.</li></ol><blockquote name="425a" id="425a" class="graf graf--blockquote graf-after--li"><em class="markup--em markup--blockquote-em">This situation makes startups particularly interesting, as they start from scratch (zero-to-one) and donâ€™t face the challenges of migrating to GPT-era architectures and models, avoiding switching costs. They have nothing to lose since they begin with a clean slate. This scenario exemplifies the classic innovatorâ€™s dilemma, where established organizations face significant challenges in adapting to groundbreaking advancements, while startups, unburdened by legacy systems, have the agility to innovate and lead the charge in the GPT era.Â <br>Google vs. Perplexity | FANG? vs. OpenAI</em></blockquote><p name="9b6b" id="9b6b" class="graf graf--p graf-after--blockquote">I am curious to hear your thoughts on this topic! (ðŸ‘‡ comments) How is your company dealing with the integration of GPT-era models? How are you unblocking progressÂ ?</p><p name="7a35" id="7a35" class="graf graf--p graf-after--p">Also on linkedin</p><div name="505d" id="505d" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://www.linkedin.com/posts/prdeepak_databricks-dais-innovatorsdilemma-activity-7211287415917838336-53bd?utm_source=share&amp;utm_medium=member_desktop" data-href="https://www.linkedin.com/posts/prdeepak_databricks-dais-innovatorsdilemma-activity-7211287415917838336-53bd?utm_source=share&amp;utm_medium=member_desktop" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://www.linkedin.com/posts/prdeepak_databricks-dais-innovatorsdilemma-activity-7211287415917838336-53bd?utm_source=share&amp;utm_medium=member_desktop"><strong class="markup--strong markup--mixtapeEmbed-strong">Deepak Babu P R on LinkedIn: Reflections on the Databricks Data + AI Summit</strong><br><em class="markup--em markup--mixtapeEmbed-em">I had a fantastic time at the Databricks Data + AI Summit @Moscone, SFO, connecting with ~2K+ participants from diverseâ€¦</em>www.linkedin.com</a><a href="https://www.linkedin.com/posts/prdeepak_databricks-dais-innovatorsdilemma-activity-7211287415917838336-53bd?utm_source=share&amp;utm_medium=member_desktop" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="07f2bf5cffd741711350507bae3c979e" data-thumbnail-img-id="0*VlwJUv-Vtnljp3Zp" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*VlwJUv-Vtnljp3Zp);"></a></div><p name="c9e0" id="c9e0" class="graf graf--p graf-after--mixtapeEmbed">Related Reads</p><div name="3f0b" id="3f0b" class="graf graf--mixtapeEmbed graf-after--p graf--trailing"><a href="https://blog.gopenai.com/from-n-grams-to-gpt-4-the-meteoric-rise-of-large-language-models-d9e064ec7bf0" data-href="https://blog.gopenai.com/from-n-grams-to-gpt-4-the-meteoric-rise-of-large-language-models-d9e064ec7bf0" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://blog.gopenai.com/from-n-grams-to-gpt-4-the-meteoric-rise-of-large-language-models-d9e064ec7bf0"><strong class="markup--strong markup--mixtapeEmbed-strong">From N-grams to GPT-4: The Meteoric Rise of Large Language Models</strong><br><em class="markup--em markup--mixtapeEmbed-em">Large Language Models (LLMs) have caused a paradigm shift in the way NLP is traditionally done i.e anything to do withâ€¦</em>blog.gopenai.com</a><a href="https://blog.gopenai.com/from-n-grams-to-gpt-4-the-meteoric-rise-of-large-language-models-d9e064ec7bf0" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="ac46aa495334186ffed9a4e91f29c4b2" data-thumbnail-img-id="1*ChubSji0BNPU499IUSz-Rw.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*ChubSji0BNPU499IUSz-Rw.png);"></a></div></div></div></section>

<hr>

<p><em>Originally published on Medium:</em> <a href="https://medium.com/@prdeepak.babu/reflections-on-the-databricks-data-ai-summit-experiments-to-production-52a8044eedda">https://medium.com/@prdeepak.babu/reflections-on-the-databricks-data-ai-summit-experiments-to-production-52a8044eedda</a></p>
